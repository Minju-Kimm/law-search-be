#!/usr/bin/env python3
"""
ê¸°ì¡´ ë¬¸ì„œì— body_ngram í•„ë“œ ì¶”ê°€ (ì¬ìƒ‰ì¸)

PostgreSQLì—ì„œ ë°ì´í„°ë¥¼ ì½ì–´ body_ngramì„ ìƒì„±í•˜ê³ 
Meilisearchì— ì¬ìƒ‰ì¸í•©ë‹ˆë‹¤.

ì‹¤í–‰ ë°©ë²•:
    python scripts/reindex_with_ngram.py

í™˜ê²½ë³€ìˆ˜ í•„ìš”:
    MEILI_HOST, MEILI_KEY, DATABASE_URL
"""
import os
import sys
import time
import httpx
from dotenv import load_dotenv
from sqlalchemy import create_engine, text

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ sys.pathì— ì¶”ê°€
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from app.services.textproc import prepare_document_for_indexing

load_dotenv()

MEILI_HOST = os.getenv("MEILI_HOST")
MEILI_KEY = os.getenv("MEILI_KEY")
DATABASE_URL = os.getenv("DATABASE_URL")

INDEXES = {
    "CIVIL_CODE": os.getenv("MEILI_INDEX_CIVIL", "civil-articles"),
    "CRIMINAL_CODE": os.getenv("MEILI_INDEX_CRIMINAL", "criminal-articles")
}

BATCH_SIZE = 500  # í•œ ë²ˆì— ìƒ‰ì¸í•  ë¬¸ì„œ ìˆ˜


def fetch_documents_from_db(law_code: str):
    """
    PostgreSQLì—ì„œ ë¬¸ì„œ ê°€ì ¸ì˜¤ê¸°

    Args:
        law_code: ë²•ë ¹ ì½”ë“œ (CIVIL_CODE, CRIMINAL_CODE)

    Returns:
        ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
    """
    engine = create_engine(DATABASE_URL)

    query = text("""
        SELECT
            law_code as "lawCode",
            article_no as "articleNo",
            article_sub_no as "articleSubNo",
            jo_code as "joCode",
            heading,
            body,
            notes,
            clauses
        FROM articles
        WHERE law_code = :law_code
        ORDER BY article_no, article_sub_no
    """)

    try:
        with engine.connect() as conn:
            result = conn.execute(query, {"law_code": law_code})
            docs = []
            for row in result:
                doc = dict(row._mapping)
                # JSONB í•„ë“œëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€
                docs.append(doc)

        return docs

    except Exception as e:
        print(f"âŒ DB ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return []


def reindex_to_meilisearch(index_name: str, docs: list, batch_size: int = BATCH_SIZE):
    """
    Meilisearchì— ì¬ìƒ‰ì¸ (ë°°ì¹˜ ì²˜ë¦¬)

    Args:
        index_name: ì¸ë±ìŠ¤ëª…
        docs: ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
        batch_size: ë°°ì¹˜ í¬ê¸°

    Returns:
        ì„±ê³µ ì—¬ë¶€
    """
    if not docs:
        print("âš ï¸  ìƒ‰ì¸í•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
        return False

    # body_ngram ì¶”ê°€
    print(f"âš™ï¸  body_ngram ìƒì„± ì¤‘... ({len(docs)}ê°œ ë¬¸ì„œ)")
    prepared_docs = []
    for i, doc in enumerate(docs):
        prepared = prepare_document_for_indexing(doc)
        prepared_docs.append(prepared)

        if (i + 1) % 100 == 0:
            print(f"   ì²˜ë¦¬ ì¤‘: {i + 1}/{len(docs)}")

    print(f"âœ… body_ngram ìƒì„± ì™„ë£Œ")

    # ë°°ì¹˜ë¡œ ë‚˜ëˆ„ì–´ ìƒ‰ì¸
    total_batches = (len(prepared_docs) + batch_size - 1) // batch_size
    print(f"ğŸ“¦ ë°°ì¹˜ ìƒ‰ì¸ ì‹œì‘ (ë°°ì¹˜ í¬ê¸°: {batch_size}, ì´ {total_batches}ê°œ ë°°ì¹˜)")

    url = f"{MEILI_HOST}/indexes/{index_name}/documents"
    headers = {"Authorization": f"Bearer {MEILI_KEY}"}

    task_uids = []

    for batch_idx in range(total_batches):
        start_idx = batch_idx * batch_size
        end_idx = min((batch_idx + 1) * batch_size, len(prepared_docs))
        batch = prepared_docs[start_idx:end_idx]

        print(f"\nğŸ“¤ ë°°ì¹˜ {batch_idx + 1}/{total_batches} ìƒ‰ì¸ ì¤‘... ({len(batch)}ê°œ ë¬¸ì„œ)")

        try:
            with httpx.Client(timeout=60.0) as client:
                response = client.post(url, headers=headers, json=batch)

                if response.status_code == 202:
                    task_data = response.json()
                    task_uid = task_data.get("taskUid")
                    task_uids.append(task_uid)
                    print(f"âœ… ë°°ì¹˜ ìƒ‰ì¸ ìš”ì²­ ì„±ê³µ (Task UID: {task_uid})")
                else:
                    print(f"âŒ ë°°ì¹˜ ìƒ‰ì¸ ì‹¤íŒ¨: {response.status_code}")
                    print(f"   ì‘ë‹µ: {response.text[:200]}")
                    return False

        except Exception as e:
            print(f"âŒ ë°°ì¹˜ ìƒ‰ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
            return False

        # ë°°ì¹˜ ê°„ ì§€ì—° (ì„œë²„ ë¶€í•˜ ë°©ì§€)
        if batch_idx < total_batches - 1:
            time.sleep(0.5)

    # ëª¨ë“  íƒœìŠ¤í¬ ì™„ë£Œ ëŒ€ê¸°
    print(f"\nâ³ ìƒ‰ì¸ íƒœìŠ¤í¬ ì™„ë£Œ ëŒ€ê¸° ì¤‘... ({len(task_uids)}ê°œ)")
    all_succeeded = wait_for_tasks(task_uids)

    if all_succeeded:
        print(f"âœ… ëª¨ë“  ë°°ì¹˜ ìƒ‰ì¸ ì™„ë£Œ")
        return True
    else:
        print(f"âš ï¸  ì¼ë¶€ ë°°ì¹˜ ìƒ‰ì¸ ì‹¤íŒ¨")
        return False


def wait_for_tasks(task_uids: list, timeout: int = 300):
    """
    ì—¬ëŸ¬ íƒœìŠ¤í¬ ì™„ë£Œ ëŒ€ê¸°

    Args:
        task_uids: íƒœìŠ¤í¬ UID ë¦¬ìŠ¤íŠ¸
        timeout: íƒ€ì„ì•„ì›ƒ (ì´ˆ)

    Returns:
        ëª¨ë“  íƒœìŠ¤í¬ ì„±ê³µ ì—¬ë¶€
    """
    start_time = time.time()
    pending_tasks = set(task_uids)

    while pending_tasks and (time.time() - start_time < timeout):
        for task_uid in list(pending_tasks):
            url = f"{MEILI_HOST}/tasks/{task_uid}"
            headers = {"Authorization": f"Bearer {MEILI_KEY}"}

            try:
                with httpx.Client(timeout=10.0) as client:
                    response = client.get(url, headers=headers)

                    if response.status_code == 200:
                        task_data = response.json()
                        status = task_data.get("status")

                        if status == "succeeded":
                            pending_tasks.remove(task_uid)
                            print(f"   âœ… Task {task_uid} ì™„ë£Œ")
                        elif status == "failed":
                            error = task_data.get("error", {})
                            print(f"   âŒ Task {task_uid} ì‹¤íŒ¨: {error}")
                            pending_tasks.remove(task_uid)
                            return False

            except Exception as e:
                print(f"   âš ï¸  Task {task_uid} í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")

        if pending_tasks:
            time.sleep(2)

    if pending_tasks:
        print(f"âš ï¸  íƒ€ì„ì•„ì›ƒ: {len(pending_tasks)}ê°œ íƒœìŠ¤í¬ ë¯¸ì™„ë£Œ")
        return False

    return True


def verify_index(index_name: str, expected_count: int):
    """
    ì¸ë±ìŠ¤ ìƒ‰ì¸ ê²°ê³¼ í™•ì¸

    Args:
        index_name: ì¸ë±ìŠ¤ëª…
        expected_count: ì˜ˆìƒ ë¬¸ì„œ ìˆ˜
    """
    url = f"{MEILI_HOST}/indexes/{index_name}/stats"
    headers = {"Authorization": f"Bearer {MEILI_KEY}"}

    try:
        with httpx.Client(timeout=10.0) as client:
            response = client.get(url, headers=headers)

            if response.status_code == 200:
                stats = response.json()
                doc_count = stats.get("numberOfDocuments", 0)
                print(f"\nğŸ“Š ì¸ë±ìŠ¤ í†µê³„:")
                print(f"   - ë¬¸ì„œ ìˆ˜: {doc_count} / {expected_count}")
                print(f"   - ìƒ‰ì¸ ì¤‘: {stats.get('isIndexing', False)}")

                if doc_count >= expected_count:
                    print(f"   âœ… ìƒ‰ì¸ ì™„ë£Œ í™•ì¸")
                else:
                    print(f"   âš ï¸  ë¬¸ì„œ ìˆ˜ê°€ ì˜ˆìƒë³´ë‹¤ ì ìŠµë‹ˆë‹¤")

            else:
                print(f"âš ï¸  í†µê³„ í™•ì¸ ì‹¤íŒ¨: {response.status_code}")

    except Exception as e:
        print(f"âš ï¸  í†µê³„ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("=" * 60)
    print("ğŸ”„ Meilisearch ì¬ìƒ‰ì¸ ìŠ¤í¬ë¦½íŠ¸ (body_ngram ì¶”ê°€)")
    print("=" * 60)
    print(f"ğŸ“ í˜¸ìŠ¤íŠ¸: {MEILI_HOST}")
    print(f"ğŸ“‹ ëŒ€ìƒ ì¸ë±ìŠ¤:")
    for law_code, index_name in INDEXES.items():
        print(f"   - {law_code} â†’ {index_name}")
    print()

    # í™˜ê²½ë³€ìˆ˜ í™•ì¸
    if not all([MEILI_HOST, MEILI_KEY, DATABASE_URL]):
        print("âŒ í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤:")
        print("   - MEILI_HOST")
        print("   - MEILI_KEY")
        print("   - DATABASE_URL")
        sys.exit(1)

    # Meilisearch í—¬ìŠ¤ì²´í¬
    try:
        with httpx.Client(timeout=5.0) as client:
            response = client.get(f"{MEILI_HOST}/health")
            if response.status_code != 200:
                print(f"âŒ Meilisearch ì„œë²„ ì‘ë‹µ ì—†ìŒ: {response.status_code}")
                sys.exit(1)
        print("âœ… Meilisearch ì„œë²„ ì—°ê²° ì„±ê³µ\n")
    except Exception as e:
        print(f"âŒ Meilisearch ì„œë²„ ì—°ê²° ì‹¤íŒ¨: {e}")
        sys.exit(1)

    # ê° ë²•ë ¹ë³„ ì¬ìƒ‰ì¸
    results = {}

    for law_code, index_name in INDEXES.items():
        print(f"\n{'='*60}")
        print(f"ğŸ“‹ {law_code} â†’ {index_name}")
        print("=" * 60)

        # DBì—ì„œ ë¬¸ì„œ ê°€ì ¸ì˜¤ê¸°
        print(f"ğŸ“¥ PostgreSQLì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ëŠ” ì¤‘...")
        docs = fetch_documents_from_db(law_code)

        if not docs:
            print(f"âš ï¸  ë¬¸ì„œê°€ ì—†ê±°ë‚˜ ì¡°íšŒ ì‹¤íŒ¨")
            results[index_name] = False
            continue

        print(f"âœ… ë¬¸ì„œ {len(docs)}ê°œ ê°€ì ¸ì˜´")

        # ì¬ìƒ‰ì¸
        success = reindex_to_meilisearch(index_name, docs)
        results[index_name] = success

        if success:
            # ìƒ‰ì¸ ê²°ê³¼ í™•ì¸
            verify_index(index_name, len(docs))

    # ìµœì¢… ê²°ê³¼
    print("\n" + "=" * 60)
    print("ğŸ“Š ìµœì¢… ê²°ê³¼")
    print("=" * 60)

    all_success = True
    for index_name, success in results.items():
        status = "âœ… ì„±ê³µ" if success else "âŒ ì‹¤íŒ¨"
        print(f"{status} - {index_name}")
        if not success:
            all_success = False

    if all_success:
        print("\nğŸ‰ ëª¨ë“  ì¬ìƒ‰ì¸ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        print("\nğŸ’¡ ë‹¤ìŒ ë‹¨ê³„:")
        print("   1. ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì‹¤í–‰")
        print("   2. body_ngram í•„ë“œ í™•ì¸")
        print("   3. ê²€ìƒ‰ í’ˆì§ˆ ê°œì„  í™•ì¸")
        sys.exit(0)
    else:
        print("\nâš ï¸  ì¼ë¶€ ì¬ìƒ‰ì¸ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        print("\nğŸ”§ ë¬¸ì œ í•´ê²°:")
        print("   1. Meilisearch ë¡œê·¸ í™•ì¸")
        print("   2. ë””ìŠ¤í¬ ìš©ëŸ‰ í™•ì¸")
        print("   3. ì¸ë±ìŠ¤ ì„¤ì • í™•ì¸ (scripts/setup_meili.py)")
        sys.exit(1)


if __name__ == "__main__":
    main()
